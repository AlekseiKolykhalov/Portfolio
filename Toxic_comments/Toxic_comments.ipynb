{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ токсичности комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучим модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Значение метрики качества *F1*  должно быть не меньше 0.75. \n",
    "\n",
    "**План работы**  \n",
    "1. Изучим данные;\n",
    "2. Очистим и лемматизируем текст;\n",
    "3. Подготовим признаки;\n",
    "4. Подберем гиперпараметры и обучим модели классификации;\n",
    "5. Определим лучшую модель и проверим ее качество на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "import spacy\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from fast_ml.model_development import train_valid_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('toxic_comments.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обнаружили дисбаланс классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Очистим текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    clear_text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    clear_text_split = clear_text.split()\n",
    "    return ' '.join(clear_text_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D aww He matches this background colour I m se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man I m really not trying to edit war It s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I can t make any real suggestions on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                          clear_text  \n",
       "0  Explanation Why the edits made under my userna...  \n",
       "1  D aww He matches this background colour I m se...  \n",
       "2  Hey man I m really not trying to edit war It s...  \n",
       "3  More I can t make any real suggestions on impr...  \n",
       "4  You sir are my hero Any chance you remember wh...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clear_text'] = df['text'].apply(clear_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизируем текст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем библиотеку SpaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SpaCy\n",
    "def lemma(text):\n",
    "    text = text.lower()\n",
    "    doc = nlp(text)\n",
    "    lemma_list = [token.lemma_ for token in doc]\n",
    "    return ' '.join(lemma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 25min 19s\n",
      "Wall time: 26min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['lemm_text'] = df['clear_text'].apply(lemma)  # 26 минут"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>explanation why the edit make under my usernam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D aww He matches this background colour I m se...</td>\n",
       "      <td>d aww he match this background colour I m seem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "\n",
       "                                          clear_text  \\\n",
       "0  Explanation Why the edits made under my userna...   \n",
       "1  D aww He matches this background colour I m se...   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  explanation why the edit make under my usernam...  \n",
       "1  d aww he match this background colour I m seem...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем данные на обучающую, валидационную и тестовую выборки в соотношении 3:1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['text', 'clear_text'], axis=1)  # удалим лишние признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = train_valid_test_split(df, target = 'toxic',\n",
    "                                                                            train_size=0.6, valid_size=0.2, \n",
    "                                                                            test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим размер выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95575, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(95575,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(X_train.shape)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31858, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(31858,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(X_valid.shape)\n",
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31859, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(31859,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(X_test.shape)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим признаки с учетом важности слова с помощью величины TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kolyk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')  # загрузим стоп-слова\n",
    "stopwords = nltk_stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95575, 111644)\n",
      "(31858, 111644)\n",
      "(31859, 111644)\n"
     ]
    }
   ],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)  # удалим стоп-слова\n",
    "feat_train = count_tf_idf.fit_transform(X_train['lemm_text'])\n",
    "feat_valid = count_tf_idf.transform(X_valid['lemm_text'])\n",
    "feat_test = count_tf_idf.transform(X_test['lemm_text'])\n",
    "\n",
    "# Проверим размерность\n",
    "print(feat_train.shape)\n",
    "print(feat_valid.shape)\n",
    "print(feat_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**  \n",
    "На данном этапе мы:\n",
    "1. Ознакомились с данными;\n",
    "2. Очистили и лемматизировали текст;\n",
    "3. Разбили данные на обучающую, валидационную и тестовую выборки.\n",
    "4. Создали новые признаки с помощью TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем решать задачу классификации используя следующие модели:\n",
    "\n",
    "- Решающее дерево\n",
    "- Логистическая регрессия\n",
    "- LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры {'criterion': 'gini', 'max_depth': 14}\n",
      "Tree f1_score: 0.6082434514637904\n",
      "\n",
      "CPU times: total: 23min 36s\n",
      "Wall time: 24min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = DecisionTreeClassifier(random_state=1, class_weight='balanced')\n",
    "param = {'criterion': ['gini', 'entropy'], 'max_depth': range(10, 15)}\n",
    "gscv = GridSearchCV(model, param, scoring='f1', cv=5)\n",
    "gscv.fit(feat_train, y_train)\n",
    "print('Лучшие параметры', gscv.best_params_)\n",
    "best_tree = gscv.best_estimator_\n",
    "tree_pred = best_tree.predict(feat_valid)\n",
    "score = f1_score(y_valid, tree_pred)\n",
    "print('Tree f1_score:', score)\n",
    "print()  # 22 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры {'C': 10, 'solver': 'liblinear'}\n",
      "LogisticR f1_score: 0.7453032742887816\n",
      "\n",
      "CPU times: total: 5min 17s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "param = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}\n",
    "gscv = GridSearchCV(model, param, scoring='f1', cv=5)\n",
    "gscv.fit(feat_train, y_train)\n",
    "print('Лучшие параметры', gscv.best_params_)\n",
    "best_forest = gscv.best_estimator_\n",
    "model.fit(feat_train, y_train)\n",
    "lr_pred = model.predict(feat_valid)\n",
    "score = f1_score(y_valid, lr_pred)\n",
    "print('LogisticR f1_score:', score)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7809, number of negative: 68651\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.108648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 375302\n",
      "[LightGBM] [Info] Number of data points in the train set: 76460, number of used features: 7198\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102132 -> initscore=-2.173759\n",
      "[LightGBM] [Info] Start training from score -2.173759\n",
      "[LightGBM] [Info] Number of positive: 7809, number of negative: 68651\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.111803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 372838\n",
      "[LightGBM] [Info] Number of data points in the train set: 76460, number of used features: 7144\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102132 -> initscore=-2.173759\n",
      "[LightGBM] [Info] Start training from score -2.173759\n",
      "[LightGBM] [Info] Number of positive: 7809, number of negative: 68651\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.089757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 374826\n",
      "[LightGBM] [Info] Number of data points in the train set: 76460, number of used features: 7180\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102132 -> initscore=-2.173759\n",
      "[LightGBM] [Info] Start training from score -2.173759\n",
      "[LightGBM] [Info] Number of positive: 7809, number of negative: 68651\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.120818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 374460\n",
      "[LightGBM] [Info] Number of data points in the train set: 76460, number of used features: 7188\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102132 -> initscore=-2.173759\n",
      "[LightGBM] [Info] Start training from score -2.173759\n",
      "[LightGBM] [Info] Number of positive: 7808, number of negative: 68652\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.046403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 373832\n",
      "[LightGBM] [Info] Number of data points in the train set: 76460, number of used features: 7169\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102119 -> initscore=-2.173901\n",
      "[LightGBM] [Info] Start training from score -2.173901\n",
      "[LightGBM] [Info] Number of positive: 7809, number of negative: 68651\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.021934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 375302\n",
      "[LightGBM] [Info] Number of data points in the train set: 76460, number of used features: 7198\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102132 -> initscore=-2.173759\n",
      "[LightGBM] [Info] Start training from score -2.173759\n",
      "[LightGBM] [Info] Number of positive: 7809, number of negative: 68651\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.014396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 372838\n",
      "[LightGBM] [Info] Number of data points in the train set: 76460, number of used features: 7144\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102132 -> initscore=-2.173759\n",
      "[LightGBM] [Info] Start training from score -2.173759\n",
      "[LightGBM] [Info] Number of positive: 7809, number of negative: 68651\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.054921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 374826\n",
      "[LightGBM] [Info] Number of data points in the train set: 76460, number of used features: 7180\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102132 -> initscore=-2.173759\n",
      "[LightGBM] [Info] Start training from score -2.173759\n",
      "[LightGBM] [Info] Number of positive: 7809, number of negative: 68651\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.047057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 374460\n",
      "[LightGBM] [Info] Number of data points in the train set: 76460, number of used features: 7188\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102132 -> initscore=-2.173759\n",
      "[LightGBM] [Info] Start training from score -2.173759\n",
      "[LightGBM] [Info] Number of positive: 7808, number of negative: 68652\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.091848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 373832\n",
      "[LightGBM] [Info] Number of data points in the train set: 76460, number of used features: 7169\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102119 -> initscore=-2.173901\n",
      "[LightGBM] [Info] Start training from score -2.173901\n",
      "[LightGBM] [Info] Number of positive: 7809, number of negative: 68651\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.032738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 375302\n",
      "[LightGBM] [Info] Number of data points in the train set: 76460, number of used features: 7198\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102132 -> initscore=-2.173759\n",
      "[LightGBM] [Info] Start training from score -2.173759\n",
      "[LightGBM] [Info] Number of positive: 7809, number of negative: 68651\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.028584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 372838\n",
      "[LightGBM] [Info] Number of data points in the train set: 76460, number of used features: 7144\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102132 -> initscore=-2.173759\n",
      "[LightGBM] [Info] Start training from score -2.173759\n",
      "[LightGBM] [Info] Number of positive: 7809, number of negative: 68651\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.113605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 374826\n",
      "[LightGBM] [Info] Number of data points in the train set: 76460, number of used features: 7180\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102132 -> initscore=-2.173759\n",
      "[LightGBM] [Info] Start training from score -2.173759\n",
      "[LightGBM] [Info] Number of positive: 7809, number of negative: 68651\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.106641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 374460\n",
      "[LightGBM] [Info] Number of data points in the train set: 76460, number of used features: 7188\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102132 -> initscore=-2.173759\n",
      "[LightGBM] [Info] Start training from score -2.173759\n",
      "[LightGBM] [Info] Number of positive: 7808, number of negative: 68652\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.033127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 373832\n",
      "[LightGBM] [Info] Number of data points in the train set: 76460, number of used features: 7169\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102119 -> initscore=-2.173901\n",
      "[LightGBM] [Info] Start training from score -2.173901\n",
      "[LightGBM] [Info] Number of positive: 7809, number of negative: 68651\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.123965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 375302\n",
      "[LightGBM] [Info] Number of data points in the train set: 76460, number of used features: 7198\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102132 -> initscore=-2.173759\n",
      "[LightGBM] [Info] Start training from score -2.173759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7809, number of negative: 68651\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.115682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 372838\n",
      "[LightGBM] [Info] Number of data points in the train set: 76460, number of used features: 7144\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102132 -> initscore=-2.173759\n",
      "[LightGBM] [Info] Start training from score -2.173759\n",
      "[LightGBM] [Info] Number of positive: 7809, number of negative: 68651\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.118228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 374826\n",
      "[LightGBM] [Info] Number of data points in the train set: 76460, number of used features: 7180\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102132 -> initscore=-2.173759\n",
      "[LightGBM] [Info] Start training from score -2.173759\n",
      "[LightGBM] [Info] Number of positive: 7809, number of negative: 68651\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.113204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 374460\n",
      "[LightGBM] [Info] Number of data points in the train set: 76460, number of used features: 7188\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102132 -> initscore=-2.173759\n",
      "[LightGBM] [Info] Start training from score -2.173759\n",
      "[LightGBM] [Info] Number of positive: 7808, number of negative: 68652\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.045993 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 373832\n",
      "[LightGBM] [Info] Number of data points in the train set: 76460, number of used features: 7169\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102119 -> initscore=-2.173901\n",
      "[LightGBM] [Info] Start training from score -2.173901\n",
      "[LightGBM] [Info] Number of positive: 9761, number of negative: 85814\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.554857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 440554\n",
      "[LightGBM] [Info] Number of data points in the train set: 95575, number of used features: 8273\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102129 -> initscore=-2.173787\n",
      "[LightGBM] [Info] Start training from score -2.173787\n",
      "Лучшие параметры {'learning_rate': 0.3, 'num_leaves': 30}\n",
      "[LightGBM] [Info] Number of positive: 9761, number of negative: 85814\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.499606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 440554\n",
      "[LightGBM] [Info] Number of data points in the train set: 95575, number of used features: 8273\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102129 -> initscore=-2.173787\n",
      "[LightGBM] [Info] Start training from score -2.173787\n",
      "LGBM f1_score: 0.7821901323706378\n",
      "\n",
      "CPU times: total: 24min 40s\n",
      "Wall time: 6min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = lgb.LGBMClassifier()\n",
    "param = {'num_leaves': [20, 30], 'learning_rate': [0.1, 0.3]}\n",
    "gscv = GridSearchCV(clf, param, scoring='f1', cv=5)\n",
    "gscv.fit(feat_train, y_train)\n",
    "print('Лучшие параметры', gscv.best_params_)\n",
    "best_light = gscv.best_estimator_\n",
    "best_light.fit(feat_train, y_train)\n",
    "light_pred = best_light.predict(feat_valid)\n",
    "score = f1_score(y_valid, light_pred)\n",
    "print('LGBM f1_score:', score)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим нашу лучшую модель на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 9761, number of negative: 85814\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.592187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 440554\n",
      "[LightGBM] [Info] Number of data points in the train set: 95575, number of used features: 8273\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102129 -> initscore=-2.173787\n",
      "[LightGBM] [Info] Start training from score -2.173787\n",
      "LGBM f1_score: 0.775856105153926\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_light.fit(feat_train, y_train)\n",
    "light_pred_test = best_light.predict(feat_test)\n",
    "score = f1_score(y_test, light_pred_test)\n",
    "print('LGBM f1_score:', score)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**  \n",
    "На данном шаге мы рассмотрели 3 модели для решения задачи классификации, подобрали гиперпараметры и получили значение f1_score для модели LightGBM = `0.78`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном проекте мы выполнили следующие этапы:\n",
    "\n",
    "1. Изучили дынные;\n",
    "2. Подготовили данные для обучения моделей (очистили и лемматизировали текст, добавили принаки);\n",
    "3. Подобрали гиперпараметры для моделей дерева решений, логистической регрессии и LightGBM;\n",
    "4. Проанализировали качество моделей;\n",
    "5. Определили модель, которая удовлетворяет условию - `LightGBM`. `f1_score` - `0.78`."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 8281,
    "start_time": "2023-10-11T13:12:40.703Z"
   },
   {
    "duration": 569,
    "start_time": "2023-10-11T13:12:57.626Z"
   },
   {
    "duration": 38,
    "start_time": "2023-10-11T13:13:09.461Z"
   },
   {
    "duration": 2575,
    "start_time": "2023-10-11T13:13:27.916Z"
   },
   {
    "duration": 34,
    "start_time": "2023-10-11T13:13:33.123Z"
   },
   {
    "duration": 9,
    "start_time": "2023-10-11T13:13:36.614Z"
   },
   {
    "duration": 10,
    "start_time": "2023-10-11T13:13:40.620Z"
   },
   {
    "duration": 10,
    "start_time": "2023-10-11T13:14:44.356Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-11T13:15:21.071Z"
   },
   {
    "duration": 4826,
    "start_time": "2023-10-11T13:15:21.600Z"
   },
   {
    "duration": 755,
    "start_time": "2023-10-11T13:15:33.308Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-11T13:15:34.064Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-11T13:15:35.044Z"
   },
   {
    "duration": 1655,
    "start_time": "2023-10-11T13:15:36.548Z"
   },
   {
    "duration": 2524005,
    "start_time": "2023-10-11T13:15:48.442Z"
   },
   {
    "duration": 9,
    "start_time": "2023-10-11T13:58:28.192Z"
   },
   {
    "duration": 43,
    "start_time": "2023-10-11T13:58:30.050Z"
   },
   {
    "duration": 3925,
    "start_time": "2023-10-11T13:58:33.232Z"
   },
   {
    "duration": 7,
    "start_time": "2023-10-11T13:58:43.049Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-11T13:58:44.402Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-11T13:58:45.683Z"
   },
   {
    "duration": 225,
    "start_time": "2023-10-11T13:58:48.245Z"
   },
   {
    "duration": 7760,
    "start_time": "2023-10-11T13:58:52.736Z"
   },
   {
    "duration": 55,
    "start_time": "2023-10-11T14:00:06.653Z"
   },
   {
    "duration": 8045,
    "start_time": "2023-10-11T14:00:31.888Z"
   },
   {
    "duration": 2509,
    "start_time": "2023-10-11T14:00:39.935Z"
   },
   {
    "duration": 34,
    "start_time": "2023-10-11T14:00:42.445Z"
   },
   {
    "duration": 18,
    "start_time": "2023-10-11T14:00:42.482Z"
   },
   {
    "duration": 31,
    "start_time": "2023-10-11T14:00:42.502Z"
   },
   {
    "duration": 16,
    "start_time": "2023-10-11T14:00:42.535Z"
   },
   {
    "duration": 4743,
    "start_time": "2023-10-11T14:00:42.553Z"
   },
   {
    "duration": 705,
    "start_time": "2023-10-11T14:00:47.298Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-11T14:00:48.005Z"
   },
   {
    "duration": 7,
    "start_time": "2023-10-11T14:00:48.011Z"
   },
   {
    "duration": 1662,
    "start_time": "2023-10-11T14:00:48.019Z"
   },
   {
    "duration": 901037,
    "start_time": "2023-10-11T14:00:49.684Z"
   },
   {
    "duration": 11,
    "start_time": "2023-10-11T14:15:50.724Z"
   },
   {
    "duration": 41,
    "start_time": "2023-10-11T14:15:50.738Z"
   },
   {
    "duration": 2850,
    "start_time": "2023-10-11T14:15:50.781Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-11T14:15:53.633Z"
   },
   {
    "duration": 40,
    "start_time": "2023-10-11T14:15:53.643Z"
   },
   {
    "duration": 15,
    "start_time": "2023-10-11T14:15:53.686Z"
   },
   {
    "duration": 167,
    "start_time": "2023-10-11T14:15:53.704Z"
   },
   {
    "duration": 2137,
    "start_time": "2023-10-11T14:15:53.873Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-11T14:15:56.011Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-11T14:15:56.013Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-11T14:15:56.017Z"
   },
   {
    "duration": 4610,
    "start_time": "2023-10-11T14:39:25.543Z"
   },
   {
    "duration": 999,
    "start_time": "2023-10-11T14:39:30.155Z"
   },
   {
    "duration": 37,
    "start_time": "2023-10-11T14:39:31.155Z"
   },
   {
    "duration": 39,
    "start_time": "2023-10-11T14:39:31.195Z"
   },
   {
    "duration": 76,
    "start_time": "2023-10-11T14:39:31.236Z"
   },
   {
    "duration": 117,
    "start_time": "2023-10-11T14:39:31.314Z"
   },
   {
    "duration": 4841,
    "start_time": "2023-10-11T14:39:31.433Z"
   },
   {
    "duration": 601,
    "start_time": "2023-10-11T14:39:36.277Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-11T14:39:36.879Z"
   },
   {
    "duration": 16,
    "start_time": "2023-10-11T14:39:36.886Z"
   },
   {
    "duration": 1651,
    "start_time": "2023-10-11T14:39:36.904Z"
   },
   {
    "duration": 2549200,
    "start_time": "2023-10-11T14:39:38.557Z"
   },
   {
    "duration": 9,
    "start_time": "2023-10-11T15:22:07.761Z"
   },
   {
    "duration": 74,
    "start_time": "2023-10-11T15:22:07.772Z"
   },
   {
    "duration": 2786,
    "start_time": "2023-10-11T15:22:07.849Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-11T15:22:10.638Z"
   },
   {
    "duration": 17,
    "start_time": "2023-10-11T15:22:10.645Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-11T15:22:10.664Z"
   },
   {
    "duration": 167,
    "start_time": "2023-10-11T15:22:10.672Z"
   },
   {
    "duration": 8117,
    "start_time": "2023-10-11T15:22:10.841Z"
   },
   {
    "duration": 1531521,
    "start_time": "2023-10-11T15:22:18.965Z"
   },
   {
    "duration": 4251598,
    "start_time": "2023-10-11T15:47:50.487Z"
   },
   {
    "duration": 174181,
    "start_time": "2023-10-11T16:58:42.088Z"
   },
   {
    "duration": 543,
    "start_time": "2023-10-11T17:01:36.275Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-11T17:02:32.313Z"
   },
   {
    "duration": 15790,
    "start_time": "2023-10-11T17:02:46.276Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-11T17:05:06.745Z"
   },
   {
    "duration": 131003,
    "start_time": "2023-10-11T17:05:58.911Z"
   },
   {
    "duration": 1369557,
    "start_time": "2023-10-11T17:08:44.989Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-11T17:37:04.485Z"
   },
   {
    "duration": 18010,
    "start_time": "2023-10-11T17:37:05.329Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-11T17:37:38.371Z"
   },
   {
    "duration": 162984,
    "start_time": "2023-10-11T17:37:40.398Z"
   },
   {
    "duration": 51138,
    "start_time": "2023-10-11T17:40:38.625Z"
   },
   {
    "duration": 42653,
    "start_time": "2023-10-11T17:42:26.010Z"
   },
   {
    "duration": 199836,
    "start_time": "2023-10-11T17:59:22.847Z"
   },
   {
    "duration": 793072,
    "start_time": "2023-10-11T18:04:01.998Z"
   },
   {
    "duration": 31,
    "start_time": "2023-10-11T18:19:49.491Z"
   },
   {
    "duration": 131449,
    "start_time": "2023-10-11T18:19:51.462Z"
   },
   {
    "duration": 2699,
    "start_time": "2023-10-11T18:22:47.290Z"
   },
   {
    "duration": 2728,
    "start_time": "2023-10-11T18:31:06.125Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-11T18:53:20.246Z"
   },
   {
    "duration": 31,
    "start_time": "2023-10-11T18:53:32.404Z"
   },
   {
    "duration": 91124,
    "start_time": "2023-10-11T18:53:56.961Z"
   },
   {
    "duration": 2374,
    "start_time": "2023-10-11T18:55:44.194Z"
   },
   {
    "duration": 4422731,
    "start_time": "2023-10-11T19:00:18.580Z"
   },
   {
    "duration": 4693,
    "start_time": "2023-10-11T20:15:01.723Z"
   },
   {
    "duration": 973,
    "start_time": "2023-10-11T20:15:06.419Z"
   },
   {
    "duration": 35,
    "start_time": "2023-10-11T20:15:07.393Z"
   },
   {
    "duration": 20,
    "start_time": "2023-10-11T20:15:07.430Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-11T20:15:07.452Z"
   },
   {
    "duration": 4624,
    "start_time": "2023-10-11T20:15:07.457Z"
   },
   {
    "duration": 548,
    "start_time": "2023-10-11T20:15:12.083Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-11T20:15:12.632Z"
   },
   {
    "duration": 2446178,
    "start_time": "2023-10-11T20:15:12.646Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-11T20:55:58.826Z"
   },
   {
    "duration": 63,
    "start_time": "2023-10-11T20:55:58.835Z"
   },
   {
    "duration": 69,
    "start_time": "2023-10-11T20:55:58.900Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-11T20:55:58.971Z"
   },
   {
    "duration": 24,
    "start_time": "2023-10-11T20:55:58.979Z"
   },
   {
    "duration": 42,
    "start_time": "2023-10-11T20:55:59.005Z"
   },
   {
    "duration": 155,
    "start_time": "2023-10-11T20:55:59.049Z"
   },
   {
    "duration": 7403,
    "start_time": "2023-10-11T20:55:59.206Z"
   },
   {
    "duration": 1378163,
    "start_time": "2023-10-11T20:56:06.611Z"
   },
   {
    "duration": 761783,
    "start_time": "2023-10-11T21:19:04.775Z"
   },
   {
    "duration": 1453327,
    "start_time": "2023-10-11T21:31:46.561Z"
   },
   {
    "duration": 89875,
    "start_time": "2023-10-11T21:55:59.890Z"
   },
   {
    "duration": 75,
    "start_time": "2023-10-11T21:57:29.767Z"
   },
   {
    "duration": 16,
    "start_time": "2023-10-11T22:00:41.991Z"
   },
   {
    "duration": 16,
    "start_time": "2023-10-11T22:01:33.953Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-11T22:02:09.980Z"
   },
   {
    "duration": 364,
    "start_time": "2023-10-11T22:02:32.771Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-11T22:02:58.983Z"
   },
   {
    "duration": 23,
    "start_time": "2023-10-11T22:03:17.554Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-11T22:03:32.832Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-11T22:03:45.478Z"
   },
   {
    "duration": 16,
    "start_time": "2023-10-11T22:06:39.128Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-11T22:06:55.782Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
